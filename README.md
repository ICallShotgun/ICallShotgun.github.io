# Introduction:

Since the transition from religion to science as humanity's main epistemological methodology for establishing the "truths" of reality, humans have obsessed over the idea of scientific categorization and compartmentalization of the world. While there is much to be said for the efficiency that the movement brings in organizing objects into groups based on relationships or patterns observed, there is also a degree of ruthlessness in the ongoing attempt to quantify it all. On one hand, quantification of the human language has allowed for the creation of the online world which has fundamentally changed the efficiency and spread of human communication, commerce and cooperation. On the other hand, quantification of the human life has allowed for widespread discrimination to exist in a language that is often not accessible to the general public. While it is fairly easy to spot bias that exists in tests and their stated objectives, the same cannot be said for bias in algorithms as they, as well as their objectives, are not explicitly stated.

While much can be said about the wide and unregulated use of algorithms for the collection and processing of our lives as data, this article is interested in revealing the translation/adaptation of the resume by the applicant tracking system (ATS). Unbeknownst to most applicants to Fortune 500 companies, an estimated 95% of the companies utilize an ATS as the first set of eyes that look over a resume. (https://www.topresume.com/career-advice/what-is-an-ats-resume). This is significant for two reasons. First, there is a false assumption that in the transposition of the paper resume to a digital one that the document will still be read visually as if you were handing in your resume to a recruiter. Second, there is a false assumption that the written text will be translated in the way in which we draw meaning from the text. These are both important in understanding our bias in thinking these ways as well as what the ATS wizard is doing on the other side of the curtain.

# Historical Context:

The inherent desire to have a standardized and universal method for arriving at a conclusion which can constitute a "truth" is not new, however, and has been the focal point of any epistemological view of the world. Epistemology refers to the study of knowledge by nature of its methods, scope and perceived validity. Historically, the dominant epistemology Western epistemology was Christianity and its methodology referred to ecclesiastical interpretation of its scriptures by church authority with regard to answering questions of the surrounding world. Those who did not obey the findings of the church, usually scientists, were subject to numerous punishments that ranged from excommunication (effectively a social "death") to imprisonment, torture and eventual death. An overhaul of the system came in the 19th-20th centuries as religious authority grew increasingly fractured and was eventually replaced by the more accepted belief in scientific authority.

Perhaps unsurprisingly, one of the first focuses of the scientists in charge was to claim absolute authority in the creation of that which was truth and that which was not. The epistemology that won out on the authority to do so is known as "logical positivism." Although it has numerous facets to its "scripture," the most important one was a test which designated anything which could not be observed, measured, and quantified for mathematical proof, as "science." As "science" now had the authority to define what people should believe, the implications of failing the test can be equated to the censorship of excommunication. In a potentially inadvertent effect, many fields of science like psychology, which relied on subjective, qualitative analysis instead of "objective", quantitative analysis, were given the same inferiority of validity in their claims as was given to religion. Additionally, with the change in epistemology also came the change in dominant state ideology to that of scientism or the belief that the scientific method is the sole determiner of truth.

Scientism is perhaps most damaging for its application of scientific methods to realms that their scopes do not expand to (like religion). As well, as with any change in power, the linguistic terminology used to favor the new dominant system changed, equating "truth, rational, objective and quantitative" with credibility reserved for "science." Anything that is "not science" is therefore "false, irrational, subjective, and qualitative." Contrary to popular belief, religion is not the opposite of science despite their historical representation as foils to one another. Rather their relationship is a conflict of power while their belief systems depend on the same foundationalism fallacies of the Münchhausen trilemma which afflict every epistemology. Regardless of the rejection of logical positivism, the methodology along with some of its more damaging terminology associations still persist.

## Operational Definitions:

One such holdover of this methodology is the concept of operational definitions. Their original use was in the field of physics, a "hard science" and de-facto member of the "science" group, which needed a way to define its unobservable concepts so that they would not fall into the category of "belief." The solution was to measure a phenomena by proxy through relating the variable in question to other observable and empirically testable phenomena such as measuring lightyears in m/s. At best these were meant to serve as a placeholder for the variable with acknowledgement of its questionable validity as an indirect measure rather than a definitive one. Nonetheless, fields previously excommunicated from the sciences disregarded the questions of validity and rapidly began to deploy the method in quantifying its qualitative studies. Most notorious for this was the field of psychology as it began to popularize measurement of an individual's worth through abstractions like the IQ test as a measure of intelligence.

## Artificial Intelligence/Machine Learning:

Computational linguistics, for the uninitiated, was a field originally started in the 1950's with the intention of using computers to translate text between different languages. Upon realizing limitations of resources and knowledge on hand, the field evolved into an intensive effort towards understanding how to represent and process natural languages with computers (NLP referring to Natural Language Processing in this article). As such, computational linguists working with en-US, the language code for specifying American English (whereas en-GB would refer to United Kingdom English), usually handle the creation of algorithms by teaching them American English rules of syntax and semantics. Syntax refers to the grammatical structure while semantics determine a value's meaning and relationships. For instance, couch flies lazily (subject verb adverb) is syntactically valid but semantically invalid. It is important to understand that valid syntax and semantics are not referring to the underlying programming language, like Python, that an algorithm might be coded in but rather how the algorithm reads and derives meaning from the American English language.

# The Resume:

Despite the density of topics listed above, it is certainly not an exhaustive analysis of how we have ended up with our current application process. That being said, the information is to inspire dialogue for the reader by having them ask questions about the processes that they take for granted as objective evaluators of their worth. How much do you really know about what each piece of information you've included in your resume means to the employer?

This subject is of particular interest to me both as someone on the lookout for good employment opportunities as well as someone who spends a good amount of time arbitrarily deciding other's value as a contract recruiter. Since I spend so much time going through and critiquing others' resumes on the basis of what does or does not fit our abstractions of success, I thought it would be interesting to evaluate my own. However, unlike the ATS model, I do all of the sorting by hand and am very familiar with the bias that sets in after parsing, scoring and documenting candidates for hours on end. Additionally, ATS systems can also check to verify some of the information people put on their resumes which can help discourage those that try to game the system.

Nonetheless, no matter how much I dislike systems that aim to label, categorize or abstract an individual's worth based on arbitrary measures of success, ATS models are not going anywhere any time soon. The best then that I can do is to try and shed light on the practices of the industry and to help those that might be unwittingly discriminated against by the syntax or the semantics they choose to represent themselves with.

![Resume](/HQ Resume.png)

# The ATS Resume:

For my adaptation, I decided to translate my resume into the language that an ATS parses to determine whether or not it is a syntactically and semantically equivalent representation of myself in the new medium. I submitted a PDF of my resume to a PDF to text converter (.txt files are what most models look at because they remove "unnecessary code") located [here](https://pdftotext.com/). The output, as shown below, should indicate that this adaptation is more of a commentary than a transposition.

![Adaptation](/ATS Text.png)

As I forfeited the agency in how my resume adapted to the new medium, like anyone who submits to an ATS does, the bias of my expectation versus reality becomes the topic of discussion. Other than shedding light on the biases I held as to how everyone would be looking at my resume, it also informed why I have gotten rejections or lukewarm responses from large corporations I have applied to. I am sure most people can relate to the feeling of failure that accompanies a slew of people telling you that your skills weren't quite up to the scrutiny of what recruiters were looking for. Instead, my failure was one of misunderstanding the expectation of formatting for applications. Therefore, rather than to abstract this failure with a depersonalized resume, especially as I did not do the actual adaptation, I decided to share my own failure for the benefit of anyone who has made the same mistakes I have.

## My Subjective Reading vs. Model "Objective" Reading:

There are three main biases I notice for how I read my resume versus how the model reads it: file formatting bias, visual hierarchy bias and font bias.

I attribute file formatting bias to specifically what can be converted to .txt format. Given that an ATS can only interpret text, anything that is not text cannot be converted into a readable format in the .txt file. As it stands, ATS systems do best with resumes saved as a docx file while only some ATS models can handle PDFs. Despite its PDF format, my resume converted okay, however, in looking at my resume which has many non-text elements and comparing it against the adaptation, none of the colors, pictures, or icon replacements for bullet points are translated into the document. Depending on the modernity of each ATS model's conversion script, other omitted elements can include anything that is included in document headers/footers. While an omission is the best outcome in these scenarios, on the basis of the overall rhetoric of my resume, they are incredibly damaging because in their unintended creation of space or lack thereof in the output, I am losing out on the original argument which took its place.

The visual hierarchy bias is similar to file formatting bias in that there is a disconnect between what we expect would happen for the decompiling of a file into text strings. This specifically relates to our creation of visual hierarchy by using grids and cells for how our resumes should be read. In my resume, for instance, the left most column is designed to catch reader attention at the top left corner with the image, like what would normally happen for English readers. However instead of continuing from left to right, then top to bottom, it directs the eyes down through the left hand, third of the page. Unfortunately, by reference of what actually occurs in the .txt output, the ATS does not detect the rows or columns in the grid and instead reads left to right, top to bottom. This is undoubtedly the biggest mistake as the text in the left hand column is randomly appended, out of context, to whatever the previous line in the right, two thirds of the document was discussing. This is especially damaging as not only does it turn the .txt file into a parsing nightmare but it turns the syntactic analysis of the grammar of my document into a series of false positives for someone who doesn't understand English. As most are likely aware, spelling and grammar issues are the quickest way to disqualify your resume from the applicant pool and my resume is no exception in this regard.

The last model bias is probably one of the more ambiguous issues to contend with as one would assume that the font of a text would output exactly as it currently looks in the text editor. There is no cue as to why it would do otherwise unless one is familiar with the complexities of decoding construction of fonts through pixel alignment and spacing. There are four types of fonts - serif, sans-serif, decorative, and script. Each of which has its own subclassifications for style patterns that it appears within. ATS models are notorious for only interpreting serif and sans-serif fonts with unreadable fonts replaced with tofu (appears a series of squares). As can be seen by the serif font, Enriqueta, which I use for the body of my text, there is no issue with how it is translated into the .txt language standard of Calibri. Contrary to that, the heading text in the sans-serif font of Comfortaa translates in all caps and with spaces in between each of the letters. This is a big issue for people knowledgeable with parsing as unexpected spaces and capitals can throw off how the model determines the end of a sentence and thus can further compound issues of visual hierarchy bias. Essentially there is little expectation that my resume would retain its titles in extraction into the ATS documentation.

## Cultural Significance:

More than likely the reader has experienced an application rejection from online submissions before. As this adaptation deals with just the preprocessing of a resume into a "readable" format, the significance of this text is limited to automatic rejections that may occur due to the conversion output. Unfortunately it is impossible to draw on the significance of that because the reason that someone was rejected is almost never shared with them, particularly if it is in relation to revealing a company's usage of an ATS.

The problem with many of these models according to Cathy O'Neil, a former Wall Street statistician for modeling Big Data, is whether or not they fit into her taxonomy for what she deems to be "Weapons of Math Destruction (WMDs)." The taxonomy is a threefold classification system with each WMD having some measure of Opacity, Scale and Damage (O'Neil, 27-30).

### Questions to ask:
* Opacity: "Even if the participant is aware of being modeled, or what the model is used for, is the model opaque, or even invisible?"
* Damage: "Does the model work against the subject's interest? In short, is it unfair? Does it damage or destroy lives?"
* Scale: "Does the model have the capacity to grow exponentially?"


# Rhetorical Situation:

In short, this is a good place to examine in depth who your adaptation addresses, what it will persuade them of, and the consequence of that persuasion, i.e. your outcomes. To aid you, this might be a good place to revisit some theorists that discussed how texts subordinate audiences to mere consumers (Debord) and those who thought texts can be emancipatory or liberating (Zizek).



# Reflection:

Consider concluding with a final reflection about your process and decision making. Try answering one or more of the following questions.
1. If someone outside this class (like your intended audience) acutally viewed your artifact, what might they think of you (the artist). Avoid answers like, “I’m a good student!” and instead, think about how your art object is a reflection of your character.
2. If you had abundant time and resources, what would you do differently for your adaptation?
3. In what situation outside of class/school might this project might be applicable and how so?

Without a doubt, my artifact is a very personal representation of myself as it is my current, generalized resume (minus my direct contact details).

If given more time and resources, I would love to embed an ATS in a webpage and have people submit their resumes in an attempt to beat the system. I think it would be interesting if I could encode feedback associated with failures determined by algorithm parameters regarding the syntactical and semantical rules the system used to arrive at its decision. I think the biggest issue with any sort of test is a lack of transparency as to what the data means in its interpretation by the test parameters. It would be even more interesting to look at the cognitive biases that are encoded into the algorithm by nature of the systems ability to discriminate outside of the syntax necessary to parse the data. The main risk of trying to define membership of qualitative objects to any group is the decision that the model is close enough.

# MLA Works Cited Page:
